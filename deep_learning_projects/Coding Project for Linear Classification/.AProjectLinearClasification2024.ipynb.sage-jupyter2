{"backend_state":"init","kernel":"python3","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"last_ipynb_save":1761105254838,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"type":"settings"}
{"cell_type":"code","exec_count":0,"id":"ded196","input":"","pos":21,"type":"cell"}
{"cell_type":"code","exec_count":11,"id":"6196fe","input":"#Complete the code below\n\n# Import necessary libraries for data visualization and manipulation\nimport matplotlib.pyplot as plt # For plotting and visualizing images\nimport numpy as np # For numerical operations, if needed\n# Import PyTorch libraries for data handling and transformations\nfrom torchvision import datasets, transforms  # For loading and transforming datasets\nfrom torch.utils.data import DataLoader  # For creating data loaders to handle batches\n#####################################################################\n# Data preprocessing transformations: Declare the variable transform that:\n# -Convert images to PyTorch tensors, \n# -Normalize to range [-1, 1]\n#complete the line below\ntransform =  transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=(0.5,), std=(0.5,))])# Convert images to PyTorch tensors\n              # Normalizes pixel values to mean 0.5 and std 0.5, scaling to range [-1, 1]\n\n#####################################################################\n\n#####################################################################\n#Define the Dataset.MNIST variables train_dataset, testdataset with parameters\n# - root='./data': Saves the dataset to a local 'data' directory\n# - train=True: Loads the training set (60,000 images)\n# - download=True: Downloads the dataset if it is not already in the specified directory\n# - transform=transform: Applies the defined transformations to the dataset\n# Download and load MNIST training and test datasets\n#Complete the following two lines of code\ntrain_dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\ntest_dataset = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n#####################################################################\n\n#####################################################################\n# DataLoader for batching and shuffling\nbatch_size = 64  # Number of images per batch\n\n#Define two Dataloader variables: train_loader and test_loader\n#Parameters of the DataLoader call for training:\n# - batch_size=64: Defines the number of images in each batch\n# - shuffle=True: Shuffles the training dataset for better learning (randomizes each epoch)\n#Complete the line below\n# the variable will take its data from the train_dataset variable defined above\ntrain_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n\n#Parameters of the DataLoader call for testing:\n# - batch_size=64: Defines the number of images in each batch\n# - shuffle=false: Does not shuffle the test dataset to maintain consistency during evaluation\n#Complete the line below\n# the variable will take its data from the test_dataset variable defined above\ntest_loader = DataLoader(test_dataset, batch_size, shuffle=False)","pos":6,"type":"cell"}
{"cell_type":"code","exec_count":13,"id":"ad5505","input":"# Complete the code below\n\n#####################################################################\n# Retrieve the first batch of train_loader and store it as images and labels \nexamples = next(iter(test_loader))   # Create an iterator for the training data called examples\nimages, labels = examples  # Get the first batch of images and labels\n#print the shapeof the tensors `images` and `labels`.\nprint(\"shape of tensor images: \", images.shape)\nprint(\"shape of tensor labels: \", labels.shape)\n#####################################################################\n\n#####################################################################\n# Display a few images from `images` with their `labels`\nfor i in range(6):\n    plt.subplot(2, 3, i+1)  # Create a 2x3 grid of subplots\n    plt.imshow(images[i][0], cmap='gray')  # Show the image (only 1 channel for grayscale)\n    plt.title(f'Label: {labels[i].item()}')  # Display the label\n    plt.axis('off')\nplt.show()\n#####################################################################","output":{"0":{"name":"stdout","output_type":"stream","text":"shape of tensor images:  torch.Size([64, 1, 28, 28])\nshape of tensor labels:  torch.Size([64])\n"},"1":{"data":{"image/png":"a03c5288fd2e98d11990be21082bfe9f816850f5","text/plain":"<Figure size 1200x700 with 6 Axes>"},"exec_count":13,"metadata":{"image/png":{"height":580,"width":921}},"output_type":"execute_result"}},"pos":8,"type":"cell"}
{"cell_type":"code","exec_count":16,"id":"83e193","input":"# Write your answer here\n\n# Define the linear model\ninput_size = 28 * 28  # Each image is 28x28 pixels\nnum_classes = 10  # Digits 0-9\nmodel = nn.Sequential(nn.Flatten(),   # Flatten each 28x28 image into a 784-dimensional vector\n                      nn.Linear(input_size, num_classes)   # Single linear layer with 10 output nodes\n                     )\n# Initialize weights with a small Gaussian noise, biases as zero\nmodel[1].weight.data = torch.normal(0, 0.01, size=(num_classes, input_size), requires_grad=True)\n\nmodel[1].bias.data = torch.zeros(num_classes, requires_grad=True)\n\nprint(\"Model structure:\\n\", model)","output":{"0":{"name":"stdout","output_type":"stream","text":"Model structure:\n Sequential(\n  (0): Flatten(start_dim=1, end_dim=-1)\n  (1): Linear(in_features=784, out_features=10, bias=True)\n)\n"}},"pos":10,"type":"cell"}
{"cell_type":"code","exec_count":17,"id":"356100","input":"#Complete the code below\n\n# Cross-entropy loss function (common for classification tasks) renamed as criterion\ncriterion = nn.CrossEntropyLoss()\n\n# Define the lr value and Stochastic Gradient Descent (SGD) optimizer\nlearning_rate = 0.01  # The step size for weight updates\noptimizer = optim.SGD(model.parameters(), lr=learning_rate)","pos":12,"type":"cell"}
{"cell_type":"code","exec_count":3,"id":"d567fc","input":"# PyTorch for neural network and tensor operations\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\n# Matplotlib for visualizing data and results\nimport matplotlib.pyplot as plt","pos":1,"type":"cell"}
{"cell_type":"code","exec_count":34,"id":"a292ec","input":"#Complete the code below\n#####################################################################\n#We initialize the required parameters\nepochs = 5  # Number of times to iterate over the entire dataset (full training process)\naccuracies = []  # List to store accuracy values for each epoch\nlearning_rate = 0.01  # The step size for weight updates\n#####################################################################\n\n#####################################################################\n#We Reinitialize Model Parameters and we reset the Optimizer\n#so that we can rerun this code with different parameters.\n\n#Before starting a new training run, reinitialize the model's parameters to random values (as they were during the first initialization).\ntorch.nn.init.normal_(model[1].weight, mean=0.0, std=0.01)\ntorch.nn.init.constant_(model[1].bias, 0)\n\n# Reset Optimizer: Recreate the optimizer with the new learning rate and ensure it uses the reinitialized model's parameters.\noptimizer = optim.SGD(model.parameters(), lr=learning_rate)\n#####################################################################\n\n#####################################################################\n#We train now\nfor epoch in range(epochs):  # Loop over each epoch\n    total_loss = 0  # Initialize the cumulative loss for the current epoch\n    correct = 0  # Initialize the count of correctly predicted labels for the epoch\n    total = 0  # Initialize the total number of labels processed in the epoch\n    \n    # Iterate over the data loader, which provides batches of images and their corresponding labels\n    for images, labels in train_loader:\n        # Flatten the 28x28 image tensors into 1D vectors of size 784\n        # I dont see why this is necessary as the model flattens the input itself\n        \n        # Perform a forward pass through the model to get output predictions\n        outputs = model(images)\n        \n        # Compute the loss using the defined criterion (e.g., CrossEntropyLoss)\n        loss = criterion(outputs,labels)\n        \n        # Clear any previously accumulated gradients in the optimizer\n        optimizer.zero_grad()\n        \n        # Perform backpropagation to compute gradients of the loss w.r.t. model parameters\n        loss.backward()\n        \n        # Update the model parameters using the computed gradients\n        optimizer.step()\n        \n        # Track training metrics\n        total_loss += loss.item()  # Add the loss for this batch to the cumulative loss\n        \n        # Determine the predicted class with the highest probability\n        _, predicted = outputs.max(1)  # `max(1)` returns the max value and its index for each sample along dim 1\n        \n        # Count the total number of labels in the batch\n        total += labels.size(0)\n        \n        # Count how many predictions match the true labels\n        correct += (predicted == labels).sum().item()\n\n    # After all batches in the epoch, calculate accuracy\n    accuracy = 100 * correct / total  # Convert accuracy to a percentage\n    accuracies.append(accuracy)  # Store accuracy for plotting\n    \n    # Print the metrics for the current epoch\n    print(f'Epoch [{epoch+1}/{epochs}], Loss: {total_loss:.4f}, Accuracy: {accuracy:.2f}%')\n\n#####################################################################\n# Plot epochs vs accuracy\nplt.figure(figsize=(6, 4))\nplt.plot(range(1, epochs + 1), accuracies, marker='o', linestyle='-', label='Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy (%)')\nplt.title('Epochs vs Accuracy')\nplt.grid(True)\nplt.legend()\nplt.show()\n#####################################################################","output":{"0":{"name":"stdout","output_type":"stream","text":"Epoch [1/5], Loss: 567.9644, Accuracy: 85.04%\n"},"1":{"name":"stdout","output_type":"stream","text":"Epoch [2/5], Loss: 361.9403, Accuracy: 89.35%\n"},"2":{"name":"stdout","output_type":"stream","text":"Epoch [3/5], Loss: 329.9061, Accuracy: 90.17%\n"},"3":{"name":"stdout","output_type":"stream","text":"Epoch [4/5], Loss: 313.7467, Accuracy: 90.51%\n"},"4":{"name":"stdout","output_type":"stream","text":"Epoch [5/5], Loss: 303.5333, Accuracy: 90.74%\n"},"5":{"data":{"image/png":"b1a790982b5f96112c81a46f7892c1af3708fe51","text/plain":"<Figure size 600x400 with 1 Axes>"},"exec_count":34,"metadata":{"image/png":{"height":392,"width":532}},"output_type":"execute_result"}},"pos":14,"type":"cell"}
{"cell_type":"code","exec_count":35,"id":"bf14ba","input":"# Write your code here\n# Evaluation on the test set\n# Switch the model to evaluation mode to ensure proper behavior during evaluation\n# (e.g., disables dropout and batch normalization updates).\nmodel.eval()\n\n# Disable gradient computation since we are only evaluating the model and not updating weights.\n# This reduces memory usage and speeds up the computation.\nwith torch.no_grad():  \n    correct = 0  # Initialize the count of correct predictions\n    total = 0  # Initialize the total number of samples in the test set\n\n    # Loop through the test data loader, which provides batches of images and labels.\n    for images, labels in test_loader:\n        # Flatten each 28x28 image into a 1D vector of size 784 to match the input shape expected by the model.\n        # I dont see why this is necessary as the model flattens the input itself\n        \n        # Perform a forward pass to obtain model predictions for the batch of images.\n        outputs = model(images)\n        \n        # `outputs.max(1)` returns the maximum value and its index for each row in the batch (dim=1).\n        # The index corresponds to the predicted class (e.g., 0-9 for digits in MNIST).\n        _, predicted = outputs.max(1)\n        \n        # Count the number of labels in the current batch and add it to the total count.\n        total += labels.size(0)\n        \n        # Compare the predicted labels to the true labels and count the number of correct predictions.\n        correct += (predicted == labels).sum().item()\n    \n    # Calculate the overall accuracy as a percentage.\n    # Accuracy = (Number of correct predictions / Total number of samples) * 100\n    accuracy = 100 * correct / total\n    \n    # Print the test accuracy in percentage format.\n    print(f'Test Accuracy: {accuracy:.2f}%')","output":{"0":{"name":"stdout","output_type":"stream","text":"Test Accuracy: 91.36%\n"}},"pos":16,"type":"cell"}
{"cell_type":"code","exec_count":4,"id":"bc227d","input":"import matplotlib.pyplot as plt  # For plotting images\nfrom torchvision import datasets  # For loading the MNIST dataset\n\n# Download and load the MNIST dataset\n# `root='./data'` specifies where to store the dataset\n# `train=True` loads the training set (set to False for the test set)\n# `download=True` ensures the dataset is downloaded if not already present\nmnist_data = datasets.MNIST(root='./data', train=True, download=True)\n\n# Function to display a specified number of images from the dataset\ndef show_images(dataset, num_images=5):\n    # Create a figure with a row of subplots\n    # `figsize=(10, 2)` controls the size of the entire figure\n    fig, axes = plt.subplots(1, num_images, figsize=(10, 2))\n    \n    # Loop through the first `num_images` items in the dataset\n    for i in range(num_images):\n        # Retrieve the image and label for the current item\n        image, label = dataset[i]\n        \n        # Display the image on the i-th subplot\n        # `cmap=\"gray\"` displays the image in grayscale\n        axes[i].imshow(image, cmap=\"gray\")\n        \n        # Set the title for the current subplot to show the label\n        axes[i].set_title(f\"Label: {label}\")\n        \n        # Turn off axis markers for a cleaner look\n        axes[i].axis(\"off\")\n    \n    # Show the figure with all images\n    plt.show()\n\n# Call the function to display 5 items from the dataset\nshow_images(mnist_data, 5)","output":{"0":{"name":"stdout","output_type":"stream","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n"},"1":{"name":"stdout","output_type":"stream","text":"Failed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"},"10":{"name":"stderr","output_type":"stream","text":"\r100%|██████████| 28.9k/28.9k [00:00<00:00, 1.96MB/s]"},"11":{"name":"stdout","output_type":"stream","text":"Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"},"12":{"name":"stderr","output_type":"stream","text":"\n"},"13":{"name":"stdout","output_type":"stream","text":"Failed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n"},"14":{"name":"stdout","output_type":"stream","text":"Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"},"15":{"name":"stderr","output_type":"stream","text":"\r  0%|          | 0.00/1.65M [00:00<?, ?B/s]"},"16":{"name":"stderr","output_type":"stream","text":"\r 78%|███████▊  | 1.28M/1.65M [00:00<00:00, 11.4MB/s]"},"17":{"name":"stderr","output_type":"stream","text":"\r100%|██████████| 1.65M/1.65M [00:00<00:00, 14.3MB/s]"},"18":{"name":"stderr","output_type":"stream","text":"\n"},"19":{"name":"stdout","output_type":"stream","text":"Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n"},"2":{"name":"stderr","output_type":"stream","text":"\r  0%|          | 0.00/9.91M [00:00<?, ?B/s]"},"20":{"name":"stdout","output_type":"stream","text":"Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"},"21":{"name":"stderr","output_type":"stream","text":"\r  0%|          | 0.00/4.54k [00:00<?, ?B/s]"},"22":{"name":"stderr","output_type":"stream","text":"\r100%|██████████| 4.54k/4.54k [00:00<00:00, 7.05MB/s]"},"23":{"name":"stdout","output_type":"stream","text":"Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n\n"},"24":{"name":"stderr","output_type":"stream","text":"\n"},"25":{"data":{"image/png":"e4358b685f66086525dd6f734938e1ce52612913","text/plain":"<Figure size 1000x200 with 5 Axes>"},"exec_count":4,"metadata":{"image/png":{"height":174,"width":795}},"output_type":"execute_result"},"3":{"name":"stderr","output_type":"stream","text":"\r  9%|▉         | 918k/9.91M [00:00<00:01, 7.77MB/s]"},"4":{"name":"stderr","output_type":"stream","text":"\r100%|██████████| 9.91M/9.91M [00:00<00:00, 49.2MB/s]"},"5":{"name":"stderr","output_type":"stream","text":"\n"},"6":{"name":"stdout","output_type":"stream","text":"Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"},"7":{"name":"stdout","output_type":"stream","text":"\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n"},"8":{"name":"stdout","output_type":"stream","text":"Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"},"9":{"name":"stderr","output_type":"stream","text":"\r  0%|          | 0.00/28.9k [00:00<?, ?B/s]"}},"pos":3,"type":"cell"}
{"cell_type":"code","exec_count":44,"id":"ce58a5","input":"# Write your code here\n\n# Display predictions for a few images\nexamples = next(iter(test_loader))          # Create an iterator for the test data\nimages, labels = examples                   # Get the first batch of images and labels\noutputs = model(images)                     # Forward pass for predictions\npredictions = torch.argmax(outputs, dim=1)  # Get index of max probability for each image\n\n# Display a few images with their predictions and true labels\nfor i in range(6):\n    plt.subplot(2, 3, i+1)\n    plt.imshow(images[i][0], cmap='gray')  # Show the image\n    plt.title(f'Actual: {labels[i].item()}, Predicted: {predictions[i].item()}')\n    plt.axis('off')\nplt.show()","output":{"0":{"data":{"image/png":"dfab1882ab5f7be45e9a0c5c300f02ae2c337157","text/plain":"<Figure size 1200x700 with 6 Axes>"},"exec_count":44,"metadata":{"image/png":{"height":580,"width":921}},"output_type":"execute_result"}},"pos":18,"type":"cell"}
{"cell_type":"markdown","id":"0e1e0c","input":"### **3. Data Visualization**\n\n#### **Objective**:\nVisualize a few images from the dataset to gain familiarity with the input data format and content.\n\n**Instructions**:\n1. Extract the first batch of images and labels from the variable `train_dataloader`.\n2. Store that batch into the tensor variables `images`, `labels`.\n3. Print the shapes of the tensors `images` and `labels`.\n4. Print the first vector in the tensor `images`.\n\nThe code defined at the end of the code below prints the first 6 elements of `images` and `labels` as images and numbers.\n\nThe output that you should get after you complete the code below and execute it correctly should be similar to:\n\n![images1](images1.png)","pos":7,"type":"cell"}
{"cell_type":"markdown","id":"3f9fd7","input":"### **5. Loss Function and Optimizer**\n\n#### **Objective**:\nDefine the loss function and optimizer, which will help the model learn.\n\n**Instructions**:\n1. **Cross-Entropy Loss**: Use cross-entropy to measure the difference between predicted probabilities and actual labels, which is suitable for classification tasks. You may use the `nn.CrossEntropyLoss()` method from the class `nn`. Rename the `nn.CrossEntropyLoss()` as `criterion` so it is easier to write in what follows.\n\n2. **Stochastic Gradient Descent (SGD)**: Set up the optimizer as a variable called `optimizer` to update weights to minimize the loss following the SGD method. USe the `optim.SGD` with the learning rate set at 0.01. \n","pos":11,"type":"cell"}
{"cell_type":"markdown","id":"4ebd12","input":"### **4. Model Definition**\n\n#### **Objective**:\nDefine a linear classification model that maps input images to output classes.\n\n#### `nn.Sequential` in PyTorch\n\nThe `nn.Sequential` class in PyTorch provides a simple way to build a neural network by stacking layers sequentially. \n\nIt allows you to define a feed-forward model with a series of layers, such as fully connected layers, convolutional layers, or activation functions, in the order they should be executed. \n\nThis approach is particularly useful for creating straightforward models that do not require complex, non-linear layer connections or branching.\n\n#### Using `nn.Sequential` in Classification Tasks\n\nIn classification tasks, `nn.Sequential` is often used to define the sequence of operations that process input data through layers and activation functions, ultimately producing class probabilities. \n\nFor example, a simple neural network can be built using `nn.Sequential` as follows:\n\n```python\nimport torch\nimport torch.nn as nn\n\n# Define a simple feed-forward neural network for classification\nmodel = nn.Sequential(\n    nn.Flatten(),           # Flatten the input (e.g., 28x28 image to 784 vector)\n    nn.Linear(784, 128),    # Fully connected layer with 784 inputs and 128 outputs\n    nn.ReLU(),              # ReLU activation function\n    nn.Linear(128, 64),     # Fully connected layer with 128 inputs and 64 outputs\n    nn.ReLU(),              # ReLU activation function\n    nn.Linear(64, 10),      # Final layer with 64 inputs and 10 outputs (for 10 classes)\n    nn.Softmax(dim=1)       # Softmax activation to output probabilities for each class\n)\n```\n\nIn this example:\n\n* Layers are added sequentially, where each layer’s output feeds directly into the next layer.\n\n* Activation Functions (e.g., ReLU and Softmax) are placed between layers to introduce non-linearities, enabling the model to learn complex patterns.\n\n* The last layer typically outputs a vector representing class probabilities, allowing for straightforward prediction by taking the class with the highest probability.\nnn.Sequential is particularly effective for standard classification tasks, making the model architecture both readable and concise.\n\n**Activity Instructions**:\n\nFirst,  define the variable `model` of type `nn.sequential`. This variable will contain a single layer with 10 output nodes.\nFor your variable `model`:\n\n1. Flatten each 28x28 pixel image into a 784-dimensional vector.\n\n2. Use a single linear layer to map the input vector to a 10-dimensional output (one for each digit class).\n\n3. Initialize the weights and biases as follows: the weights to be randomly assigned form a distribution with mean $0$ and standard deviation $0.01$, and the bias to be assigned the initial value of $0$.\n\nYour output should look like this:\n\n![output3](Output3.png)","pos":9,"type":"cell"}
{"cell_type":"markdown","id":"7ef284","input":"**END OF WORKSHEET**\n\nMake sure that you answered all the questions on time. This completed `Jupyter Notebook` will be collected and graded. \n\nOnce the `Jupyter Notebook` is collected it can not be modified.","pos":20,"type":"cell"}
{"cell_type":"markdown","id":"8d6497","input":"### **2. Data Preparation**\n\n#### **Objective**:\n\n> To download and prepare the MNIST dataset for training and testing. We will normalize the images and convert them to tensors.\n\n#### The MNIST Dataset\n\nThe **MNIST (Modified National Institute of Standards and Technology)** dataset is a large collection of handwritten digits commonly used for training and testing machine learning models, especially in computer vision. It includes **70,000 grayscale images** of handwritten digits (0 through 9), each **28x28 pixels** in size:\n\n- **Training Set**: 60,000 images\n- **Test Set**: 10,000 images\n\nEach image in MNIST is labeled with the correct digit (0–9), making it an ideal dataset for tasks like classification and digit recognition.\n\n#### Key Options in the `torchvision.datasets` Module for MNIST\n\nThe `torchvision.datasets` module provides an easy way to load and preprocess the MNIST dataset. Below are some important parameters when using `datasets.MNIST`:\n\n- **`root`**: The directory where the dataset will be stored. If it doesn't exist, it will be created.\n  \n- **`train`**: If set to `True`, loads the training set (60,000 images). If `False`, loads the test set (10,000 images).\n\n- **`download`**: If `True`, downloads the dataset to the specified `root` directory if it is not already available.\n\n- **`transform`**: Accepts a transformation or series of transformations (like `ToTensor`) to apply to the images. For example, `transforms.ToTensor()` converts PIL images to PyTorch tensors and normalizes the pixel values to the range [0, 1].\n\n#### Example Usage\n\nThe code below gives a simple example of the retrieval and displaying of the data items in the database MNIST using the torchvision.datasets module. \n","pos":2,"type":"cell"}
{"cell_type":"markdown","id":"8dca1d","input":"**Activity Instructions**:\n\nFor our purpose we need to input the data from MNIST with three important modifications\n\n\nCreate a transform variable called `transform`  that does:\n1. **Normalization**: Normalize the pixel values from [0, 255] to [-1, 1] to help the network train more effectively.\n2.  **Transforms**  from images to tensors.\n\nOnce this variable `transform` is defined, use it as a parameter to the `datasets.MNIST`  call to create two variables: `train_dataset` and `test_dataset`.\n\n2. **Batching**: Use the `train_dataset` and the `test_dataset` variables to create 2 instances of a `DataLoader `variable: `train_dataloader` and `test_dataloader`. When you define these datalaoder instances makes sure that you select a `batch_size` of 32. ","pos":5,"type":"cell"}
{"cell_type":"markdown","id":"91299b","input":"# **Project: Linear Classification with PyTorch**\n\n### **Objective**:\nTo develop a simple linear classification neural network using PyTorch. This project will involve creating, training, and evaluating a model on the MNIST dataset, allowing students to understand the core components of building neural networks for classification tasks.\n\n### **Prerequisites**:\n- Basic understanding of Python programming\n- Familiarity with matrix operations and probability\n- Introduction to neural networks and the concept of classification\n\n---\n\n## **Table of Contents**:\n\n1. [Setup and Imports](#1-setup-and-imports)\n2. [Data Preparation](#2-data-preparation)\n3. [Data Visualization](#3-data-visualization)\n4. [Model Definition](#4-model-definition)\n5. [Loss Function and Optimizer](#5-loss-function-and-optimizer)\n6. [Training the Model](#6-training-the-model)\n7. [Testing the Model](#7-testing-the-model)\n8. [Model Prediction Visualization](#8-model-prediction-visualization)\n\n---\n\n### **1. Setup and Imports**\n\n#### **Objective**:\nInitialize the environment by importing essential libraries needed for building, training, and visualizing the neural network model.\n","pos":0,"type":"cell"}
{"cell_type":"markdown","id":"97567b","input":"### **6. Training the Model**\n\n#### **Objective**:\nTrain the model over multiple epochs by feeding it batches of training data, calculating the loss, and updating the model parameters.\n\n**Loop Steps**:\n1. **Forward Pass**: Compute model predictions for each batch.\n2. **Backward Pass**: Calculate the gradients of the loss with respect to model parameters.\n3. **Optimizer Step**: Update model parameters using the calculated gradients.\n\nYour output should be similar to:\n\n![output](output.png)","pos":13,"type":"cell"}
{"cell_type":"markdown","id":"bb1e19","input":"### **8. Model Prediction Visualization**\n\n#### **Objective**:\n\nVisualize a few predictions to understand the model’s performance visually.\n\n**Instructions**:\n\n1. Display sample images with predicted and actual labels to see the model’s accuracy on specific cases. ","pos":17,"type":"cell"}
{"cell_type":"markdown","id":"d16a89","input":"### **7. Testing the Model**\n\n#### **Objective**:\nEvaluate the model's accuracy on unseen test data to assess generalization.\n\n**Instructions**:\n1. **Evaluation Mode**: Disable gradient computation and backpropagation by setting the model to evaluation mode.\n2. Compute accuracy on the test dataset by comparing predictions with true label with the predictions obtained from your optimized neural network. The dataloader to use in this case is the `test_dataloader`, NOT the `train_dataloader`.\n\nYour output should be similar to this:\n\n![accuracy](accuracy.png)","pos":15,"type":"cell"}
{"cell_type":"markdown","id":"d5aa6d","input":"<div class=\"alert alert-block alert-info\">\n<b>NOTE</b> It is important to note that in the example above we did not implement any **transformation** to the `datasets.MNIST()` command.\n</div>\n","pos":4,"type":"cell"}
{"cell_type":"markdown","id":"f7bfe7","input":"### Summary\n\nThis notebook walks through the process of building, training, and testing a simple linear classification model on the MNIST dataset using PyTorch.\n\nBy completing these exercises, students will gain hands-on experience with the fundamental steps in building a classification neural network, including data preparation, model definition, training, and evaluation.","pos":19,"type":"cell"}
{"id":0,"time":1761105221099,"type":"user"}
{"last_load":1761105221709,"type":"file"}